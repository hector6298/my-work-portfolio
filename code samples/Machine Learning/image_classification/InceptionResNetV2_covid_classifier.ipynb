{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hector6298/Deep-Learning-Collab-notebooks/blob/master/InceptionResNetV2_covid_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zeh2uQ2QMgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv11DbxZ7CY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install pydicom\n",
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip3 install --upgrade kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GbR1YhZ41kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /root/.kaggle\n",
        "!echo '{\"username\":\"hector6298\",\"key\":\"724778e3045b27ede8002c9f01b9da72\"}' > /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZYhnB06xOLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/ieee8023/covid-chestxray-dataset.git\n",
        "!git clone https://github.com/agchung/Figure1-COVID-chestxray-dataset\n",
        "!git clone https://github.com/agchung/Actualmed-COVID-chestxray-dataset\n",
        "!kaggle datasets download -d \"tawsifurrahman/covid19-radiography-database\"\n",
        "!kaggle competitions download -c \"rsna-pneumonia-detection-challenge\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvUPlGjQx-mV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip rsna-pneumonia-detection-challenge.zip\n",
        "!rm rsna-pneumonia-detection-challenge.zip\n",
        "!unzip covid19-radiography-database.zip\n",
        "!rm covid19-radiography-database.zip\n",
        "!mkdir data\n",
        "!mkdir data/train\n",
        "!mkdir data/test\n",
        "!mkdir /content/logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSkyz7CQ-e5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 \"/content/drive/My Drive/COVID-Net-master/COVID-Net-master/create_covidx_v3.py\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiHdtwQXw6MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.exposure import equalize_adapthist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import average_precision_score\n",
        "from tensorflow.python.keras.callbacks import Callback\n",
        "from sklearn.metrics import recall_score, classification_report\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5DosRcayVMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _process_csv_file(file):\n",
        "    with open(file, 'r') as fr:\n",
        "        files = fr.readlines()\n",
        "    return files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8JtYpk-ICDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xray_enhance(img):\n",
        "  #DENOISE\n",
        "  median = cv2.medianBlur(img, 3)\n",
        "  #SHARP EDGES\n",
        "  gaussian_3 = cv2.GaussianBlur(median, (3,3), 10.0)\n",
        "  unsharp_image = cv2.addWeighted(median, 1.5, gaussian_3, -0.5, 0, median)\n",
        "  #Contrast Limited Adaptive Histogram Equalization\n",
        "  cl1 = equalize_adapthist(unsharp_image)\n",
        "  return cl1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FLfHpEbrHJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def crop_top(img, percent=0.15):\n",
        "    offset = int(img.shape[0] * percent)\n",
        "    return img[offset:]\n",
        "\n",
        "\n",
        "def process_image_file(filepath, top_percent, size):\n",
        "    img = cv2.imread(filepath)\n",
        "    img = crop_top(img, percent=top_percent)\n",
        "    img = cv2.resize(img, (size, size))\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "_augmentation_transform = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        ")\n",
        "\n",
        "def apply_augmentation(img):\n",
        "    img = _augmentation_transform.random_transform(img)\n",
        "    return img\n",
        "\n",
        "def _process_csv_file(file):\n",
        "    with open(file, 'r') as fr:\n",
        "        files = fr.readlines()\n",
        "    return files\n",
        "\n",
        "\n",
        "class BalanceCovidDataset(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            data_dir,\n",
        "            csv_file,\n",
        "            is_training=True,\n",
        "            batch_size=8,\n",
        "            input_shape=(448, 448),\n",
        "            n_classes=3,\n",
        "            num_channels=3,\n",
        "            mapping={\n",
        "                'normal': 0,\n",
        "                'pneumonia': 1,\n",
        "                'COVID-19': 2\n",
        "            },\n",
        "            shuffle=True,\n",
        "            augmentation=apply_augmentation,\n",
        "            covid_percent=0.3,\n",
        "            class_weights=[1., 1., 6.],\n",
        "            top_percent=0.08\n",
        "    ):\n",
        "        'Initialization'\n",
        "        self.datadir = data_dir\n",
        "        self.dataset = _process_csv_file(csv_file)\n",
        "        self.is_training = is_training\n",
        "        self.batch_size = batch_size\n",
        "        self.N = len(self.dataset)\n",
        "        self.input_shape = input_shape\n",
        "        self.n_classes = n_classes\n",
        "        self.num_channels = num_channels\n",
        "        self.mapping = mapping\n",
        "        self.shuffle = True\n",
        "        self.covid_percent = covid_percent\n",
        "        self.class_weights = class_weights\n",
        "        self.n = 0\n",
        "        self.augmentation = augmentation\n",
        "        self.top_percent = top_percent\n",
        "\n",
        "        datasets = {'normal': [], 'pneumonia': [], 'COVID-19': []}\n",
        "        for l in self.dataset:\n",
        "            datasets[l.split()[2]].append(l)\n",
        "        self.datasets = [\n",
        "            datasets['normal'] + datasets['pneumonia'],\n",
        "            datasets['COVID-19'],\n",
        "        ]\n",
        "        print(len(self.datasets[0]), len(self.datasets[1]))\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __next__(self):\n",
        "        # Get one batch of data\n",
        "        batch_x, batch_y, weights = self.__getitem__(self.n)\n",
        "        # Batch index\n",
        "        self.n += 1\n",
        "\n",
        "        # If we have processed the entire dataset then\n",
        "        if self.n >= self.__len__():\n",
        "            self.on_epoch_end\n",
        "            self.n = 0\n",
        "\n",
        "        return batch_x, batch_y, weights\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.datasets[0]) / float(self.batch_size)))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        if self.shuffle == True:\n",
        "            for v in self.datasets:\n",
        "                np.random.shuffle(v)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x, batch_y = np.zeros(\n",
        "            (self.batch_size, *self.input_shape,\n",
        "             self.num_channels)), np.zeros(self.batch_size)\n",
        "\n",
        "        batch_files = self.datasets[0][idx * self.batch_size:(idx + 1) *\n",
        "                                       self.batch_size]\n",
        "\n",
        "        # upsample covid cases\n",
        "        covid_size = max(int(len(batch_files) * self.covid_percent), 1)\n",
        "        covid_inds = np.random.choice(np.arange(len(batch_files)),\n",
        "                                      size=covid_size,\n",
        "                                      replace=False)\n",
        "        covid_files = np.random.choice(self.datasets[1],\n",
        "                                       size=covid_size,\n",
        "                                       replace=False)\n",
        "        for i in range(covid_size):\n",
        "            batch_files[covid_inds[i]] = covid_files[i]\n",
        "\n",
        "        for i in range(len(batch_files)):\n",
        "            sample = batch_files[i].split()\n",
        "\n",
        "            if self.is_training:\n",
        "                folder = 'train'\n",
        "            else:\n",
        "                folder = 'test'\n",
        "\n",
        "            x = process_image_file(os.path.join(self.datadir, folder, sample[1]),\n",
        "                                   self.top_percent,\n",
        "                                   self.input_shape[0])\n",
        "\n",
        "            if self.is_training and hasattr(self, 'augmentation'):\n",
        "                x = self.augmentation(x)\n",
        "\n",
        "            x = x.astype('float32') / 255.0\n",
        "            y = self.mapping[sample[2]]\n",
        "\n",
        "            batch_x[i] = x\n",
        "            batch_y[i] = y\n",
        "\n",
        "        class_weights = self.class_weights\n",
        "        weights = np.take(class_weights, batch_y.astype('int64'))\n",
        "\n",
        "        return batch_x, keras.utils.to_categorical(batch_y, num_classes=self.n_classes), weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb8nU9QU19l1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 30\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 64\n",
        "INPUT_SIZE = 224\n",
        "NCLASSES = 3\n",
        "INPUT_SHAPE = (INPUT_SIZE, INPUT_SIZE, NCLASSES)\n",
        "\n",
        "TRAINFILE = '/content/train_split_v3.txt'\n",
        "TESTFILE = '/content/test_split_v3.txt'\n",
        "DATADIR = '/content/data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJj25O4k2xbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(TRAINFILE) as f:\n",
        "    trainfiles = f.readlines()\n",
        "with open(TESTFILE) as f:\n",
        "    testfiles = f.readlines()\n",
        "\n",
        "train_generator = BalanceCovidDataset(data_dir=DATADIR,\n",
        "                                csv_file=TRAINFILE,\n",
        "                                batch_size=BATCH_SIZE,\n",
        "                                input_shape=(INPUT_SIZE, INPUT_SIZE),\n",
        "                                covid_percent=0.3,\n",
        "                                class_weights=[1., 1., 4.],\n",
        "                                top_percent=0.08)\n",
        "\n",
        "test_generator = BalanceCovidDataset(data_dir=DATADIR,\n",
        "                                csv_file=TESTFILE,\n",
        "                                batch_size=BATCH_SIZE,\n",
        "                                is_training=False,\n",
        "                                input_shape=(INPUT_SIZE, INPUT_SIZE),\n",
        "                                covid_percent=0.3,\n",
        "                                class_weights=[1., 1., 4.],\n",
        "                                top_percent=0.08)\n",
        "                                \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3VpnSwl3iI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_flag = False\n",
        "\n",
        "base_model = tf.keras.applications.InceptionResNetV2(\n",
        "    include_top=False, weights='imagenet', input_shape=INPUT_SHAPE,\n",
        ")\n",
        "base_model.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajNtGyCMEZ3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(base_model, input_shape):\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "  prediction_layer = tf.keras.layers.Dense(NCLASSES, activation='softmax')\n",
        "\n",
        "  x = inputs\n",
        "  x = base_model(x)\n",
        "  x = global_average_layer(x)\n",
        "  x = prediction_layer(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w35fEw_8zBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "METRICS = [\n",
        "  tf.keras.metrics.CategoricalAccuracy(),\n",
        "\n",
        "  keras.metrics.Precision(name='precision_0', class_id=0),\n",
        "  keras.metrics.Recall(name='recall_0', class_id=0),\n",
        "  keras.metrics.AUC(name='auc_all', multi_label=True, label_weights=[1.,1.,3.]),\n",
        "\n",
        "  keras.metrics.Precision(name='precision_1', class_id=1),\n",
        "  keras.metrics.Recall(name='recall_1', class_id=1),\n",
        "\n",
        "  keras.metrics.Precision(name='precision_2', class_id=2),\n",
        "  keras.metrics.Recall(name='recall_2', class_id=2),\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYlsTTptE_40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics = METRICS\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "model = get_model(base_model, INPUT_SHAPE)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_object,\n",
        "              metrics = metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtBF-u66FsDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkAHdGweSGDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch):\n",
        "  if epoch <= 5:\n",
        "    return 0.005\n",
        "  elif epoch > 5 and epoch <= 20:\n",
        "    return 0.001\n",
        "  else:\n",
        "    return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
        "scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/content/logs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YwrGaX7TDPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_history = model.fit(x=train_generator, \n",
        "                epochs=EPOCHS,\n",
        "                validation_data=test_generator,\n",
        "                verbose=1,\n",
        "                callbacks=[scheduler_callback, tensorboard_callback]\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuIVHkbwTLQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def plot_metrics(model_history):\n",
        "\n",
        "  loss = model_history.history['loss']\n",
        "  val_loss = model_history.history['val_loss']\n",
        "  acc = model_history.history['sparse_categorical_accuracy']\n",
        "  val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "  epochs = range(EPOCHS)\n",
        "\n",
        "  fig, axs = plt.subplots(2)\n",
        "  axs[0].plot(epochs, loss, 'r', label='Training loss')\n",
        "  axs[0].plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "\n",
        "\n",
        "  axs[1].plot(epochs, acc, 'r', label='training accuracy')\n",
        "  axs[1].plot(epochs, val_acc, 'bo', label=\"vall acc\")\n",
        "\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "  \n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCWzKgd1Tk2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_metrics(model_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B30_WM2_EVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def test_step(test_images, test_labels):\n",
        "  return model(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8sjLKDO7o_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "for j in range(len(test_generator)):\n",
        "\n",
        "    test_images, test_labels, weigths = next(test_generator)\n",
        "    #print(test_labels)\n",
        "    \n",
        "    #imgs += len(test_images)\n",
        "    predictions = test_step(test_images, test_labels)\n",
        "    predictions_classnum = np.argmax(predictions, axis=1)\n",
        "    test_labels_ = np.argmax(test_labels, axis=1)\n",
        "    confidences = np.amax(predictions)\n",
        "\n",
        "    for item in range(BATCH_SIZE):\n",
        "        y_pred.append(predictions_classnum[item])\n",
        "        y_true.append(int(test_labels_[item]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CsOCDEH_29Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_names = ['Normal', 'Pneumonia', 'COVID-19']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "\n",
        "#cm = confusion_matrix(y_true, y_pred)\n",
        "#print(cm)\n",
        "#cmn = confusion_matrix(y_true, y_pred, normalize='all')\n",
        "\n",
        "\n",
        "#df_cm = pd.DataFrame(cm, index = ['normal','pneumonia','covid-19'],\n",
        "        #          columns = ['normal','pneumonia','covid-19'])\n",
        "\n",
        "#print(df_cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ycXREG6Tnpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_config = model.to_json()\n",
        "with open('model_config.json', 'w') as json_file:\n",
        "    json_file.write(json_config)\n",
        "model.save_weights('covid_net_weights2.h5')\n",
        "files.download('covid_net_weights2.h5')\n",
        "files.download('model_config.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0g_hKSHUoLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip /content/logs.zip /content/logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY93iIMKVBUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"/content/logs.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}