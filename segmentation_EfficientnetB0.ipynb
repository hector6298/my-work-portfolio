{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segmentation_EfficientnetB7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hector6298/Deep-Learning-Collab-notebooks/blob/master/segmentation_EfficientnetB0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLiVjxj-ax02",
        "colab_type": "text"
      },
      "source": [
        "#Modified U-net with EfficientNetB7 as the encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bim6_mvwbAQh",
        "colab_type": "text"
      },
      "source": [
        "This collab is made to train a segmentation model with a custom dataset, not from tensorflow APIs.\n",
        "The dataset to be used is COCO along with its API for image filenames, classes and segmentation masks loading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cFqL3QZbdTL",
        "colab_type": "text"
      },
      "source": [
        "Thi line is just to mount your Google Drive. You can skip it if you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5It42tsETTY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgG8Ubp2fyK4",
        "colab_type": "text"
      },
      "source": [
        "Remove useless data from Collab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8SzBokafzw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r /content/sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lABZMeFKmk1r",
        "colab_type": "text"
      },
      "source": [
        "Download and set raw COCO data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT5m644iofwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "!unzip train2014.zip\n",
        "!rm train2014.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjt_5dncfs_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/val2014.zip\n",
        "!unzip val2014.zip\n",
        "!rm val2014.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsw1XUWCq123",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
        "!unzip annotations_trainval2014.zip\n",
        "!rm annotations_trainval2014.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y32A8UAgb79y",
        "colab_type": "text"
      },
      "source": [
        "Clone and install the API into the VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu7mzcQoJ-ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/nightrome/cocostuffapi.git\n",
        "!make -C cocostuffapi/PythonAPI/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqeTXPOScBpp",
        "colab_type": "text"
      },
      "source": [
        "Install tensorflow examples to use Pix2Pix for the upsamplers in the decoding part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAmVD8IbVNhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/examples.git\n",
        "!pip install --upgrade tensorflow-hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6crmwUrtmqfw",
        "colab_type": "text"
      },
      "source": [
        "##Python Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BHk4s2_LBB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.transform import resize\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "from cocostuffapi.PythonAPI.pycocotools.coco import COCO\n",
        "from cocostuffapi.PythonAPI.pycocotools.cocostuffhelper import cocoSegmentationToSegmentationMap\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWvg2q54mfS0",
        "colab_type": "text"
      },
      "source": [
        "Method to retrieve all the image Ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iWF2gSTE0qT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get all images containing given categories, select one at random\n",
        "def getIds4Categories(coco, categories):\n",
        "  idlist = []\n",
        "  classMap = dict()\n",
        "  label = 1\n",
        "  for category in categories:\n",
        "    print(f\"resolving for {category}...\")\n",
        "    catIds = coco.getCatIds(catNms=[category])\n",
        "    classMap[catIds[0]] = label\n",
        "    print(label)\n",
        "    label += 1\n",
        "    imgIds = coco.getImgIds(catIds=catIds )\n",
        "    for id in imgIds:\n",
        "      idlist.append(id)\n",
        "  return idlist, classMap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb9M1NZQmRRC",
        "colab_type": "text"
      },
      "source": [
        "Method to convert coco segmentation data into a mask for each image, given a dictionary mapping COCO classes ids to labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k7kVFMyYVJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getMask(coco, imgId, classMap, iscrowd=False, checkUniqueClass=False):\n",
        "  shape = coco.imgs[imgId]\n",
        "  shape = (shape['height'], shape['width'])\n",
        "  labelMap = np.zeros(shape)\n",
        "\n",
        "  annIds = coco.getAnnIds(imgIds=imgId, iscrowd=iscrowd)\n",
        "  imgAnns = coco.loadAnns(annIds)\n",
        "\n",
        "  for ann in imgAnns:\n",
        "    labelMask = coco.annToMask(ann) == 1\n",
        "    if ann['category_id'] in classMap:\n",
        "      newLabel = classMap[ann['category_id']]\n",
        "      labelMap[labelMask] = newLabel\n",
        "  return labelMap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg7Dfh7nmK9U",
        "colab_type": "text"
      },
      "source": [
        "This is the class that will generate all our data for training. It is subclassed from keras.utils.Sequence A useful class to easily  train a Keras model using custom data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDBEqtDhdnpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self,\n",
        "               coco,\n",
        "               imgIds,\n",
        "               datadir,\n",
        "               classMap=None,\n",
        "               is_training=True,\n",
        "               batch_size=8,\n",
        "               input_shape=(224,224),\n",
        "               num_channels = 3,\n",
        "               shuffle=True,\n",
        "               augmentationParams=None,\n",
        "               seed = 3\n",
        "               ):\n",
        "    self.coco = coco\n",
        "    self.imgIds = imgIds\n",
        "    self.batch_size = batch_size\n",
        "    self.input_shape = input_shape\n",
        "    self.num_channels = num_channels\n",
        "    self.shuffle = shuffle\n",
        "    self.datadir = datadir\n",
        "    self.classMap = classMap\n",
        "    self.imgObjs = self.coco.loadImgs(self.imgIds)\n",
        "    self.is_training = is_training\n",
        "    self.n = 0\n",
        "    self.seed = seed\n",
        "    if augmentationParams is not None:\n",
        "      self.augmentationEngineIMG = ImageDataGenerator(**augmentationParams)\n",
        "      self.augmentationEngineMASK = ImageDataGenerator(**augmentationParams)\n",
        "      \n",
        "  def __next__(self):\n",
        "    batch_x, batch_y = self.__getitem__(self.n)\n",
        "    self.n += 1\n",
        "    if self.n >= self.__len__():\n",
        "      self.on_epoch_end()\n",
        "      self.n = 0\n",
        "    return batch_x, batch_y\n",
        "  \n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.imgIds)/float(self.batch_size)))\n",
        "  \n",
        "  def reset_batch_index(self):\n",
        "    self.n = 0\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.imgObjs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    sample = self.imgObjs[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "    batch_x = np.empty((self.batch_size, self.input_shape[0], self.input_shape[1], self.num_channels), dtype=np.float32)\n",
        "    batch_y = np.empty((self.batch_size, self.input_shape[0], self.input_shape[1], 1), dtype=np.float32)\n",
        "\n",
        "    for i in range(self.batch_size):\n",
        "      img = io.imread(f\"{self.datadir}/{sample[i]['file_name']}\")\n",
        "      mask = getMask(self.coco, sample[i]['id'], self.classMap)\n",
        "      mask = np.expand_dims(mask, axis=2)\n",
        "      if(len(img.shape) < 3):\n",
        "        img = np.expand_dims(img,axis=2)\n",
        "\n",
        "      img = resize(img, self.input_shape)\n",
        "      mask = resize(mask, self.input_shape)\n",
        "\n",
        "      if self.is_training and hasattr(self,'augmentationEngineIMG'):\n",
        "        img = self.augmentationEngineIMG.random_transform(img, seed=self.seed)\n",
        "        mask = self.augmentationEngineMASK.random_transform(mask, seed=self.seed)\n",
        "      \n",
        "      batch_x[i] = img\n",
        "      batch_y[i] = mask\n",
        " \n",
        "\n",
        "    return batch_x, batch_y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtx49mI6m1lV",
        "colab_type": "text"
      },
      "source": [
        "#Main Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EojA-xYndidP",
        "colab_type": "text"
      },
      "source": [
        "##Data directories and hiperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86JkIGpydjld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataType='train2014'\n",
        "dataDirTrain='/content/train2014'\n",
        "dataDirTest='/content/val2014'\n",
        "annFileTrain='/content/annotations/instances_train2014.json'\n",
        "annFileTest='/content/annotations/instances_val2014.json'\n",
        "\n",
        "\n",
        "INPUT_SHAPE = [224,224,3]\n",
        "EPOCHS = 10\n",
        "VAL_SUBSPLITS = 5\n",
        "BATCH_SIZE = 100\n",
        "LEARNING_RATE = 0.001\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzHl7k6vnk-8",
        "colab_type": "text"
      },
      "source": [
        "**Please define the classes you want to train the model with** I wanted to segment vehicles, so I used ['bus','car','truck']\n",
        "See what classes. Run the cell below to know which classes you can use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NZo-HJmdTFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cocoTrain=COCO(annFileTrain)\n",
        "cocoTest=COCO(annFileTest)\n",
        "\n",
        "cats = cocoTrain.loadCats(cocoTrain.getCatIds())\n",
        "nms=[cat['name'] for cat in cats]\n",
        "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PorbHGHdeRHt",
        "colab_type": "text"
      },
      "source": [
        "**DEFINE YOUR CLASSES HERE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuN-4zj-m3ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES2SEGMENT= [\"person\"]\n",
        "OUTPUT_CHANNELS = len(CLASSES2SEGMENT) + 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ1nd08M7S8N",
        "colab_type": "text"
      },
      "source": [
        "Load ids for the iamges on given categories and defining a dictionary that maps category ids to labels.\n",
        "Instantiating DataGenerators; the one for the training will make use of data augmentation using the parameters given in this cell. Please change it to suit your needs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdd6Ob7mI9Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idlistTrain, classMap = getIds4Categories(cocoTrain, CLASSES2SEGMENT)\n",
        "idlistTest, classMap = getIds4Categories(cocoTest, CLASSES2SEGMENT)\n",
        "\n",
        "#dictionary for image data augmentation\n",
        "data_gen_args = dict(featurewise_center=False,\n",
        "                     featurewise_std_normalization=False,\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     horizontal_flip=True)\n",
        "\n",
        "trainImgGenerator = DataGenerator(cocoTrain, idlistTrain, dataDirTrain, classMap=classMap, batch_size=BATCH_SIZE, augmentationParams=data_gen_args)\n",
        "testImgGenerator = DataGenerator(cocoTest, idlistTest, dataDirTest, classMap=classMap, batch_size=BATCH_SIZE, is_training=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQDCD4Uiuhnf",
        "colab_type": "text"
      },
      "source": [
        "Let's test the generator to show an image and its corresponding mask showing only desired classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVIomu8fumH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_batch = len(testImgGenerator)\n",
        "batch_x, batch_y = next(testImgGenerator)\n",
        "testImgGenerator.reset_batch_index()\n",
        "\n",
        "img, mask = batch_x[0], batch_y[0]\n",
        "fig, axis = plt.subplots(1,2)\n",
        "axis[0].imshow(img)\n",
        "axis[1].imshow(tf.keras.preprocessing.image.array_to_img(mask))\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTDP5RSDedFY",
        "colab_type": "text"
      },
      "source": [
        "##Let's define the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPWLMPEb5GcA",
        "colab_type": "text"
      },
      "source": [
        "Install eficcientnet for tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aXil2L65Cnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install efficientnet\n",
        "import efficientnet.tfkeras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTAgsPT3ecWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.resnet_v2.ResNet50V2(weights='imagenet', input_shape=INPUT_SHAPE, include_top=False)\n",
        "\n",
        "layernames = [\"conv1_conv\",               #128 channels\n",
        "              \"conv2_block3_preact_relu\", #256 channels\n",
        "              \"conv3_block4_preact_relu\", #512 channels\n",
        "              \"conv4_block6_preact_relu\", #1024 channels\n",
        "              \"post_relu\"] #2048 channels   \n",
        "layers = [base_model.get_layer(name).output for name in layernames]\n",
        "downsample_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "downsample_stack.trainable = False\n",
        "\n",
        "upsample_stack = [pix2pix.upsample(1024,3),\n",
        "                  pix2pix.upsample(512,3),\n",
        "                  pix2pix.upsample(256,3),\n",
        "                  pix2pix.upsample(128,3),\n",
        "                  pix2pix.upsample(64,3)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDlgV0Ib6ypc",
        "colab": {}
      },
      "source": [
        "#base_model = tf.keras.applications.resnet_v2.ResNet50V2(weights='imagenet', input_shape=INPUT_SHAPE, include_top=False)\n",
        "\n",
        "base_model = efficientnet.tfkeras.EfficientNetB0(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
        "\n",
        "layernames = [\"block1a_project_bn\", #(112,112,16)\n",
        "              \"block2b_drop\", #(56,56,24)\n",
        "              \"block3b_drop\", #(28,28,40)\n",
        "              \"block4c_drop\", #(14,14,80) \n",
        "              \"block6d_drop\", #(7,7,192)\n",
        "              ]   \n",
        "\n",
        "layers = [base_model.get_layer(name).output for name in layernames]\n",
        "downsample_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "downsample_stack.trainable = False\n",
        "\n",
        "upsample_stack = [pix2pix.upsample(96,3),\n",
        "                  pix2pix.upsample(40,3),\n",
        "                  pix2pix.upsample(20,3),\n",
        "                  pix2pix.upsample(12,3),\n",
        "                  pix2pix.upsample(8,3),\n",
        "                  ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ymuCIq2tI8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mod_unet_efficientnet(output_channels, input_shape=[224,224,3]):\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "  x = inputs\n",
        "  #encoder\n",
        "  skips = downsample_stack(x)\n",
        "  #get last of the outputs for bottleneck\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  #decoder\n",
        "  it = 0\n",
        "  for layer_enc, skip in zip(upsample_stack, skips):\n",
        "    print(it)\n",
        "    x = layer_enc(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x,skip])\n",
        "    \n",
        "    it += 1\n",
        "\n",
        "  #last layer\n",
        "\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      output_channels, 3, strides=2, padding='same', name='outMask'\n",
        "  )\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF5_Vcele_Jt",
        "colab_type": "text"
      },
      "source": [
        "Define Our IOU metric before compiling. Default MeanIoU class does not support results from multiple channels that serves as logits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq9fK-ZZfDfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class meanIoU(tf.keras.metrics.MeanIoU):\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        y_pred = y_pred[..., tf.newaxis]\n",
        "        return super().update_state(y_true, y_pred, sample_weight=sample_weight)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FZuHKCfdpm",
        "colab_type": "text"
      },
      "source": [
        "Instantiate our model and plot the graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0XGVj7mu44i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = mod_unet_efficientnet(OUTPUT_CHANNELS)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[meanIoU(4)])\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSULSsBhvx5K",
        "colab_type": "text"
      },
      "source": [
        "##get mask inference methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn6Ztm68v2p9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mask_from_inference(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tGKHpj28zST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oif0plkAwODs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_predictions(generator=None):\n",
        "  if generator is not None:\n",
        "    batch_x, batch_y = next(generator)\n",
        "    generator.reset_batch_index()\n",
        "    pred_mask = model.predict(batch_x)\n",
        "    for i in range(5):\n",
        "      display([batch_x[i], batch_y[i], create_mask_from_inference(pred_mask[i][tf.newaxis, ...])])\n",
        "  else:\n",
        "    display([sample_image, sample_mask,\n",
        "             create_mask_from_inference(model.predict(sample_image[tf.newaxis, ...]))])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4g1LME59Q2d",
        "colab_type": "text"
      },
      "source": [
        "##Show the network is working before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb7BRkxi9P4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainImgGenerator.on_epoch_end()\n",
        "batch_x, batch_y = next(trainImgGenerator)\n",
        "\n",
        "sample_image, sample_mask = batch_x[0], batch_y[0]\n",
        "show_predictions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYJm0eqBx67d",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlC5K9ceAvIG",
        "colab_type": "text"
      },
      "source": [
        "Do we have prior weights? You can skip this cell if you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agig-8ftA3u8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists('segmentation_net_weights.h5'):\n",
        "  model.load_weights('segmentation_net_weights.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS8tdISKFOUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_mean_io_u_1',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMH7kB91CBL9",
        "colab_type": "text"
      },
      "source": [
        "Train the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQY8zBzFWWfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_history = model.fit(x=trainImgGenerator, \n",
        "                epochs=EPOCHS,\n",
        "                validation_data=testImgGenerator,\n",
        "                verbose=1,\n",
        "                callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2JyMv_0zsWy",
        "colab_type": "text"
      },
      "source": [
        "Display training metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T0x1gPpC9gIm",
        "colab": {}
      },
      "source": [
        "def plot_metrics(model_history):\n",
        "\n",
        "  loss = model_history.history['loss']\n",
        "  val_loss = model_history.history['val_loss']\n",
        "\n",
        "  iou = model_history.history['mean_io_u']\n",
        "  val_iou = model_history.history['val_mean_io_u']\n",
        "  epochs = range(EPOCHS)\n",
        "  fig, axs = plt.subplots(2)\n",
        "\n",
        "  axs[0].plot(epochs, loss, 'r', label='Training loss')\n",
        "  axs[0].plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "  axs[0].title('Training and Validation Loss')\n",
        "  axs[0].xlabel('Epoch')\n",
        "  axs[0].ylabel('Loss Value')\n",
        "  axs[1].plot(epochs, iou, 'r', label='Training iou')\n",
        "  axs[1].plot(epochs, val_iou, 'bo', label='Validation iou')\n",
        "  axs[1].title('Training and Validation iou')\n",
        "  axs[1].xlabel('Epoch')\n",
        "  axs[1].ylabel('iou Value')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNi8HfVrpvFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_metrics(model_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m3ng6Vksb1l",
        "colab_type": "text"
      },
      "source": [
        "##Save Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xm8Rx0PgE5O",
        "colab_type": "text"
      },
      "source": [
        "Save weights after training and network architechture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEAtBVhEseS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_config = model.to_json()\n",
        "with open('model_config.json', 'w') as json_file:\n",
        "    json_file.write(json_config)\n",
        "model.save_weights('segmentation_net_weights.h5')\n",
        "files.download('segmentation_net_weights.h5')\n",
        "files.downlaod('model_config.json')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}